"""
PrintDambo Module - Python Port (Optimized)
Main module for insurance terms document generation.
Contains the core logic for reading PGM, copying terms, and revising documents.

OPTIMIZATION: Uses Pandas DataLoader for bulk data reading (10-50x faster than COM)
"""
import os
import datetime
import numpy as np
from typing import Optional, List, Dict, Any, Tuple

from .word_utils import WordHandler, wdCollapseEnd, wdCollapseStart, wdSectionBreakOddPage
from .data_loader import DataLoader, ExcelWriter
from .tag_processor import TagProcessor, TagContext, create_tag_context_from_dambo_att


class DamboAttributes:
    """Data class to hold coverage attributes."""
    def __init__(self):
        self.ë‹´ë³´ì½”ë“œ = ""
        self.ëŒ€í‘œë‹´ë³´ì½”ë“œ = ""
        self.ì§„ë‹¨í™•ì • = 0
        self.ë¶€ëª¨ = 0
        self.ì˜ˆì•½ê°€ì…ì—°ë ¹ = 0
        self.ëª¨ë“ˆ = ""
        self.í˜•êµ¬ë¶„ = ""
        self.ë‹¨ì²´ = 0
        self.ìë™ê°±ì‹ í˜• = 0
        self.ë©´ì±…ê°•ì œë°˜ì˜ = ""
        self.ë©´ì±… = 0
        self.ê°ì•¡ = 0
        self.ì—°ì¥í˜• = 0
        
        # ë…ë¦½íŠ¹ì•½
        self.ë…íŠ¹ê°ì•¡ì—¬ë¶€ = ""
        self.ë…íŠ¹ë©´ì±…ì—¬ë¶€ = ""
        
        # ì„¸ë¶€ë³´ì¥ëª… (for {ì„¸ë¶€ë³´ì¥N} tag replacement)
        self.ì„¸ë¶€ë³´ì¥ëª… = ""
        self.ì„¸ë¶€ë³´ì¥ëª…_list = []  # ì¶œë ¥ë‹´ë³´ëª…ì´ ê°™ì€ ë‹´ë³´ë“¤ì˜ ë‹´ë³´ëª… ë¦¬ìŠ¤íŠ¸
        
        # ë…ë¦½íŠ¹ì•½ ì„¤ì •
        self.ë…ë¦½íŠ¹ì•½ = 0


class PrintDambo:
    """
    Main class for insurance terms document generation.
    Uses Pandas-based DataLoader for high-performance data access.
    """
    
    def __init__(self, data_loader: DataLoader):
        """
        Initialize with DataLoader instance.
        
        Args:
            data_loader: Pre-loaded DataLoader with config and PGM data
        """
        self.data = data_loader
        self.word = WordHandler()
        self.tag_processor = TagProcessor()  # Tag processing module
        
        # Column Locations (cached from data arrays)
        self.loc_í™•ì¥ë²ˆí˜¸ = 0
        self.loc_ë³´í—˜ê¸°ê°„ì—°ì¥í˜• = 0
        self.loc_ê°„í¸ê³ ì§€ = 0
        self.loc_í†µí•©ê³ ì§€ = 0
        self.loc_íƒœì•„êµ¬ë¶„ = 0
        self.loc_ë³´ê¸°ë‚©ê¸° = 0
        self.loc_ë‹´ë³´ê·¸ë£¹ = 0
        
        # ë³´ì¥êµ¬ì¡° columns
        self.loc_ë³´ì¥ë°°ìˆ˜ = 0
        self.loc_ì„¸ë¶€ë‹´ë³´ìˆœë²ˆ = 0
        self.loc_ì„¸ë¶€ë‹´ë³´ì½”ë“œ = 0
        self.loc_ê¸‰ë¶€íƒˆí‡´ìœ¨ê°œìˆ˜ = 0
        self.loc_ë‚©ë©´íƒˆí‡´ìœ¨ê°œìˆ˜ = 0
        
        # ë³´ì¥ë°°ìˆ˜ columns
        self.loc_ì§€ê¸‰ë¥  = 0
        self.loc_ë¶„í• ì§€ê¸‰ì°¨ë…„ = 0
        self.loc_ì—°ì§€ê¸‰íšŸìˆ˜ = 0
        self.loc_ë©´ì±…ê¸°ê°„ = 0
        self.loc_ê°ì•¡ê¸°ê°„ = 0
        self.loc_ê°ì•¡ê¸°ê°„2 = 0
        self.loc_ê°ì•¡ë¹„ìœ¨ = 0
        self.loc_ê°ì•¡ë¹„ìœ¨2 = 0
        self.loc_15ì„¸ë©´ì±… = 0
        
        # ì„¸ë¶€ë‹´ë³´ ê´€ë ¨
        self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ = 0
        self.ì„¸ë¶€ë‹´ë³´_bencoef = []
        self.ì„¸ë¶€ë‹´ë³´ì½”ë“œList = []
        self.m_point = 0
        self.min_riskrate_row = 0
        self.ë‚©ì…ë©´ì œì—¬ë¶€ = False
        
        # ê°ì•¡/ë©´ì±… ê´€ë ¨
        self.isê°ì•¡ë‘ë²ˆ = False
        self.sum_ë©´ì±… = 0
        self.sum_ê°ì•¡ = 0
        
        # ë³´ê¸°ë‚©ê¸° ê´€ë ¨
        self.n_array = []
        self.age_b = 0
        self.age_e = 0
        self.term_lookup_key = ""
        
        # Paths (from data_loader)
        self.ì¶œë ¥íŒŒì¼ëª… = ""
        
        # Copied terms tracking
        self.copied_list_strings = set()
        
        # Number marks â‘  â‘¡ â‘¢ etc.
        self.num_mark_arr = ["â‘ ", "â‘¡", "â‘¢", "â‘£", "â‘¤", "â‘¥", "â‘¦", "â‘§", "â‘¨", "â‘©", 
                            "â‘ª", "â‘«", "â‘¬", "â‘­", "â‘®"]
        
        # ë…ë¦½íŠ¹ì•½ ê´€ë ¨
        self.is_ë…íŠ¹ê°„í¸ = False
        self.ë…íŠ¹ë‹´ë³´ê·¸ë£¹ = 0
        self.ë…ë¦½íŠ¹ì•½ëª… = ""
        
        # Excel Writer for result saving (lazy init)
        self._excel_writer = None

    def execute(self, log_callback=None, progress_callback=None):
        """
        Main entry point for terms generation.
        Uses template data (coverage_list) for mapping results and PGM data.
        """
        try:
            if log_callback:
                log_callback("ì´ˆê¸°í™” ë° ì»¬ëŸ¼ ìœ„ì¹˜ íŒŒì•…...")
            
            # Initialize Word with performance settings
            self.word.start_app(visible=False)
            
            # Find column locations from cached arrays
            self._find_column_locations(log_callback)
            
            # Get coverage list from template_data
            template_data = getattr(self.data, 'template_data', {}) or {}
            coverage_list = template_data.get('coverage_list', [])
            
            if not coverage_list:
                if log_callback:
                    log_callback("âŒ ë‹´ë³´ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. í…œí”Œë¦¿ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return
            
            total_steps = len(coverage_list)
            
            if log_callback:
                log_callback(f"ì¢…ì†íŠ¹ì•½ ì•½ê´€ìƒì„±: {total_steps}ê°œ í•­ëª©...")
            
            # Generate output filename
            now = datetime.datetime.now()
            self.ì¶œë ¥íŒŒì¼ëª… = f"03_0_ì•½ê´€_{self.data.prod_name}_{now.strftime('%Y%m%d')}_{now.strftime('%H%M')}.docx"
            
            # ============ PRE-OPEN DOCUMENTS FOR PERFORMANCE ============
            # Open target document ONCE before loop
            target_path = getattr(self.data, 'product_doc_file', None)
            if target_path and os.path.exists(target_path):
                if log_callback:
                    log_callback(f"ğŸ“„ íƒ€ê²Ÿ ë¬¸ì„œ ì—´ê¸°: {os.path.basename(target_path)}")
                self.word.target_doc = self.word.open_doc(target_path)
            
            # Cache source documents (open once, reuse)
            self.source_docs = {}  # {file_type: doc}
            if hasattr(self, 'base_files') and self.base_files:
                if log_callback:
                    log_callback(f"ğŸ“„ ì†ŒìŠ¤ ë¬¸ì„œ {len(self.base_files)}ê°œ ì—´ê¸°...")
                for file_type, file_path in self.base_files.items():
                    doc = self.word.open_doc(file_path)
                    if doc:
                        self.source_docs[file_type] = doc
            
            # ============ OPTIMIZE WORD FOR BATCH OPERATIONS ============
            # Disable spell check, grammar check, pagination for massive speed boost
            self.word.optimize_for_batch_operations()
            if log_callback:
                log_callback("âš¡ Word ìµœì í™” ì„¤ì • ì ìš© (ë§ì¶¤ë²•/ë¬¸ë²•ê²€ì‚¬/í˜ì´ì§€ ê³„ì‚° ë¹„í™œì„±í™”)")
            
            if log_callback:
                log_callback("âœ… ë¬¸ì„œ ì¤€ë¹„ ì™„ë£Œ\n")
            
            # ============ CONNECT COMPONENTS ============
            # Connect CSVLoader to TagProcessor if available
            if hasattr(self, 'csv_loader') and self.csv_loader:
                self.tag_processor.csv_loader = self.csv_loader
                if log_callback:
                    log_callback("âœ… TagProcessorì— CSVLoader ì—°ê²° ì™„ë£Œ")
            
            # ============ GROUP BY ì¶œë ¥ë‹´ë³´ëª… FOR ì„¸ë¶€ë³´ì¥ TAGS ============
            # VBA: ì¶œë ¥ë‹´ë³´ëª…ì´ ê°™ì€ ë‹´ë³´ë“¤ì€ {ì„¸ë¶€ë³´ì¥1}, {ì„¸ë¶€ë³´ì¥2}... ìˆœë²ˆìœ¼ë¡œ ì¹˜í™˜
            # ì •ë ¬ ê¸°ì¤€: ë‹´ë³´ì½”ë“œ ì˜¤ë¦„ì°¨ìˆœ
            self.ì¶œë ¥ë‹´ë³´ëª…_groups = {}  # {ì¶œë ¥ë‹´ë³´ëª…: [(ë‹´ë³´ì½”ë“œ, ë‹´ë³´ëª…), ...]}
            for coverage in coverage_list:
                ì¶œë ¥ë‹´ë³´ëª… = str(coverage.get('ì¶œë ¥ë‹´ë³´ëª…', '') or 
                              coverage.get('ë‹´ë³´ëª…_ì¶œë ¥ë¬¼ëª…ì¹­', '') or '').strip()
                ë‹´ë³´ëª… = str(coverage.get('ë‹´ë³´ëª…', '') or 
                           coverage.get('ì„¸ë¶€ë³´ì¥ëª…', '') or '').strip()
                ë‹´ë³´ì½”ë“œ = str(coverage.get('ë‹´ë³´ì½”ë“œ', '')).strip()
                
                if ì¶œë ¥ë‹´ë³´ëª… and ë‹´ë³´ëª…:
                    if ì¶œë ¥ë‹´ë³´ëª… not in self.ì¶œë ¥ë‹´ë³´ëª…_groups:
                        self.ì¶œë ¥ë‹´ë³´ëª…_groups[ì¶œë ¥ë‹´ë³´ëª…] = []
                    self.ì¶œë ¥ë‹´ë³´ëª…_groups[ì¶œë ¥ë‹´ë³´ëª…].append((ë‹´ë³´ì½”ë“œ, ë‹´ë³´ëª…))
            
            if log_callback and self.ì¶œë ¥ë‹´ë³´ëª…_groups:
                log_callback(f"ğŸ“‹ ì¶œë ¥ë‹´ë³´ëª… ê·¸ë£¹: {len(self.ì¶œë ¥ë‹´ë³´ëª…_groups)}ê°œ")
            
            # ========================= PHASE 1: COPY & PROCESS TERMS =========================
            if log_callback:
                log_callback(f"\nğŸ“„ Phase 1: ì•½ê´€ ë³µì‚¬ ë° íƒœê·¸ ì²˜ë¦¬ ({total_steps}ê°œ)...")
            
            for i, coverage in enumerate(coverage_list):
                # Extract data from coverage dictionary (from template)
                dambo_code = str(coverage.get('ë‹´ë³´ì½”ë“œ', '')).strip()
                dambo_category = str(coverage.get('êµ¬ë¶„ê°’', '')).strip()  # From CSV mapping
                ëŒ€í‘œë‹´ë³´ì½”ë“œ = str(coverage.get('ëŒ€í‘œë‹´ë³´ì½”ë“œ', '')).strip()  # From CSV mapping
                
                if log_callback:
                    log_callback(f"  [{i+1}/{total_steps}] ì²˜ë¦¬ì¤‘: {dambo_code} ({ëŒ€í‘œë‹´ë³´ì½”ë“œ})")
                
                # Create DamboAttributes from coverage dictionary (from template)
                dambo_att = DamboAttributes()
                dambo_att.ë‹´ë³´ì½”ë“œ = dambo_code
                dambo_att.ëŒ€í‘œë‹´ë³´ì½”ë“œ = ëŒ€í‘œë‹´ë³´ì½”ë“œ
                
                # Set ë©´ì±…/ê°ì•¡/ì—°ì¥í˜• from template (already mapped from PGM)
                dambo_att.ë©´ì±… = int(coverage.get('ë©´ì±…', 0) or 0)
                dambo_att.ê°ì•¡ = int(coverage.get('ê°ì•¡', 0) or 0)
                dambo_att.ì—°ì¥í˜• = int(coverage.get('ì—°ì¥í˜•', 0) or 0)
                dambo_att.í˜•êµ¬ë¶„ = str(coverage.get('í˜•êµ¬ë¶„', '')).strip()
                
                # ëª¨ë“ˆ ì„¤ì •
                ëª¨ë“ˆ_val = coverage.get('ëª¨ë“ˆ', '')
                if ëª¨ë“ˆ_val:
                    dambo_att.ëª¨ë“ˆ = f"{ëª¨ë“ˆ_val}ëª¨ë“ˆ"
                else:
                    dambo_att.ëª¨ë“ˆ = ""
                
                dambo_att.ë‹¨ì²´ = getattr(self.data, 'ë‹¨ì²´ë³´í—˜', 0)
                dambo_att.ìë™ê°±ì‹ í˜• = getattr(self.data, 'ìë™ê°±ì‹ í˜•', 0)
                
                # ì§„ë‹¨í™•ì •, ë¶€ëª¨, ì˜ˆì•½ê°€ì…ì—°ë ¹ ì¶”ê°€
                dambo_att.ì§„ë‹¨í™•ì • = int(coverage.get('ì§„ë‹¨í™•ì •', 0) or 0)
                dambo_att.ë¶€ëª¨ = int(coverage.get('ë¶€ëª¨', 0) or 0)
                dambo_att.ì˜ˆì•½ê°€ì…ì—°ë ¹ = int(coverage.get('ì˜ˆì•½ê°€ì…ì—°ë ¹', 0) or 0)
                
                # ì„¸ë¶€ë³´ì¥ëª… ì„¤ì •
                dambo_att.ì„¸ë¶€ë³´ì¥ëª… = str(coverage.get('ì„¸ë¶€ë³´ì¥ëª…', '') or 
                                         coverage.get('ë‹´ë³´ëª…', '') or '').strip()
                
                # ì„¸ë¶€ë³´ì¥ëª…_list ì„¤ì •
                ì¶œë ¥ë‹´ë³´ëª… = str(coverage.get('ì¶œë ¥ë‹´ë³´ëª…', '') or 
                              coverage.get('ë‹´ë³´ëª…_ì¶œë ¥ë¬¼ëª…ì¹­', '') or '').strip()
                
                if ì¶œë ¥ë‹´ë³´ëª… in self.ì¶œë ¥ë‹´ë³´ëª…_groups:
                    # ë‹´ë³´ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                    group_items = self.ì¶œë ¥ë‹´ë³´ëª…_groups[ì¶œë ¥ë‹´ë³´ëª…]
                    sorted_items = sorted(group_items, key=lambda x: x[0])  # x[0] is ë‹´ë³´ì½”ë“œ
                    dambo_att.ì„¸ë¶€ë³´ì¥ëª…_list = [item[1] for item in sorted_items]  # item[1] is ë‹´ë³´ëª…
                else:
                    dambo_att.ì„¸ë¶€ë³´ì¥ëª…_list = [dambo_att.ì„¸ë¶€ë³´ì¥ëª…]
                
                # ë…ë¦½íŠ¹ì•½ ì†ì„±
                dambo_att.ë…ë¦½íŠ¹ì•½ = getattr(self.data, 'ë…ë¦½íŠ¹ì•½', 0)
                
                # Read PGM Data (CRITICAL: Must read PGM before processing tags)
                # This updates self.sum_ë©´ì±…, self.sum_ê°ì•¡, self.ì„¸ë¶€ë‹´ë³´_bencoef, etc.
                self._read_pgm_loop(dambo_code, dambo_att, i, log_callback)
                
                # ë…ë¦½íŠ¹ì•½ íŒŒì¼ ê²½ë¡œ ì¬ì§€ì •
                if self.data.ë…ë¦½íŠ¹ì•½ != 0:
                    self._set_ë…íŠ¹_file_path(dambo_att, ëŒ€í‘œë‹´ë³´ì½”ë“œ, dambo_code, log_callback)
                
                # Find source document info
                íŠ¹ë³„ì•½ê´€ê²½ë¡œ = ""
                íŠ¹ë³„ì•½ê´€íŒŒì¼ëª… = ""
                
                if hasattr(self, 'base_files') and self.base_files:
                    if dambo_category in self.base_files:
                        íŠ¹ë³„ì•½ê´€file = self.base_files[dambo_category]
                        íŠ¹ë³„ì•½ê´€ê²½ë¡œ = os.path.dirname(íŠ¹ë³„ì•½ê´€file)
                        íŠ¹ë³„ì•½ê´€íŒŒì¼ëª… = os.path.basename(íŠ¹ë³„ì•½ê´€file)
                    else:
                        if self.base_files:
                            first_file = list(self.base_files.values())[0]
                            íŠ¹ë³„ì•½ê´€ê²½ë¡œ = os.path.dirname(first_file)
                            íŠ¹ë³„ì•½ê´€íŒŒì¼ëª… = os.path.basename(first_file)
                elif self.data.arr_source_doc is not None:
                    for j in range(len(self.data.arr_source_doc)):
                        if dambo_category == str(self.data.arr_source_doc[j][0]).strip():
                            íŠ¹ë³„ì•½ê´€ê²½ë¡œ = self.data.ì¢…ì†íŠ¹ì•½ê²½ë¡œ
                            íŠ¹ë³„ì•½ê´€íŒŒì¼ëª… = str(self.data.arr_source_doc[j][1]).strip()
                            break
                
                # Copy terms AND identify the range where it was pasted
                target_range = self._copy_terms(ëŒ€í‘œë‹´ë³´ì½”ë“œ, íŠ¹ë³„ì•½ê´€ê²½ë¡œ, íŠ¹ë³„ì•½ê´€íŒŒì¼ëª…, 
                                              dambo_category, dambo_att, log_callback)
                
                # Process Tags IMMEDIATELY on the target range
                if target_range:
                    self._revise_terms(dambo_att, i, target_range, log_callback)
                
                # Update progress
                if progress_callback:
                    progress_callback(int((i + 1) / total_steps * 100))

            
            # PHASE 2 REMOVED - Tags are processed in Phase 1 loop
            pass
            
            # Final processing - 0ì„¸ìë…€ íƒœê·¸ ì²˜ë¦¬
            self._revise_ë³„í‘œ_0ì„¸(log_callback)

            # ============ RESTORE WORD SETTINGS ============
            # Restore spell check, grammar check, pagination before saving
            self.word.restore_after_batch()
            
            # Enable screen updating to show final result
            self.word.enable_screen_updating(True)
            
            # Save the modified document to output path
            output_file = getattr(self.data, 'output_file', None)
            if log_callback:
                log_callback(f"\nğŸ“‹ ì €ì¥ ì¤€ë¹„ ì¤‘...")
                log_callback(f"   ì¶œë ¥ ê²½ë¡œ: {output_file}")
                log_callback(f"   target_doc ì¡´ì¬: {self.word.target_doc is not None}")
            
            if not output_file:
                if log_callback:
                    log_callback("âŒ ì €ì¥ ì‹¤íŒ¨: ì¶œë ¥ íŒŒì¼ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            elif not self.word.target_doc:
                if log_callback:
                    log_callback("âŒ ì €ì¥ ì‹¤íŒ¨: ëŒ€ìƒ Word ë¬¸ì„œê°€ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    log_callback("   ì›ì¸: _copy_termsì—ì„œ target_docì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                try:
                    self.word.target_doc.SaveAs2(output_file)
                    if log_callback:
                        log_callback(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
                except Exception as save_err:
                    if log_callback:
                        log_callback(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {save_err}")
            
            # Close Word documents
            self.word.close_all()
            
            if log_callback:
                log_callback("\nâœ… ì•½ê´€ ìƒì„± ì™„ë£Œ!")
                
        except Exception as e:
            if log_callback:
                log_callback(f"Error: {e}")
            import traceback
            traceback.print_exc()

    def _find_column_locations(self, log_callback=None):
        """
        Find column locations in PGM arrays.
        Uses cached numpy arrays for fast lookup.
        """
        # Find column locations in Main sheet
        if self.data.arr_pgm_main is not None and len(self.data.arr_pgm_main) > 1:
            header_row = self.data.arr_pgm_main[1]  # Assuming header is row 1
            
            for i, val in enumerate(header_row):
                attr_name = str(val or "").strip().replace("\n", "")
                
                if attr_name == "ExpansionNumber":
                    self.loc_í™•ì¥ë²ˆí˜¸ = i
                elif attr_name == "ë³´í—˜ê¸°ê°„ì—°ì¥í˜•":
                    self.loc_ë³´í—˜ê¸°ê°„ì—°ì¥í˜• = i
                elif attr_name == "ZA_ConvenientDisclosureTypeScCode":
                    self.loc_ê°„í¸ê³ ì§€ = i
                elif attr_name == "ZA_DisclosureTypeScCode":
                    self.loc_í†µí•©ê³ ì§€ = i
                elif attr_name == "FetusFlag":
                    self.loc_íƒœì•„êµ¬ë¶„ = i
                elif attr_name == "ZA_CoveragePaymentInprd":
                    self.loc_ë³´ê¸°ë‚©ê¸° = i
                elif attr_name == "ë‹´ë³´ê·¸ë£¹":
                    self.loc_ë‹´ë³´ê·¸ë£¹ = i
        
        # Find column locations in ë³´ì¥êµ¬ì¡°
        if self.data.arr_ë³´ì¥êµ¬ì¡° is not None and len(self.data.arr_ë³´ì¥êµ¬ì¡°) > 0:
            header_row = self.data.arr_ë³´ì¥êµ¬ì¡°[0]
            
            for i, val in enumerate(header_row):
                attr_name = str(val or "").strip().replace("\n", "")
                
                if attr_name == "ë³´ì¥ë°°ìˆ˜":
                    self.loc_ë³´ì¥ë°°ìˆ˜ = i
                elif attr_name == "ì„¸ë¶€ë‹´ë³´ìˆœë²ˆ":
                    self.loc_ì„¸ë¶€ë‹´ë³´ìˆœë²ˆ = i
                elif attr_name == "ì„¸ë¶€ë‹´ë³´ì½”ë“œ":
                    self.loc_ì„¸ë¶€ë‹´ë³´ì½”ë“œ = i
                elif attr_name == "íƒˆí‡´ìœ¨ê°œìˆ˜":
                    if self.loc_ê¸‰ë¶€íƒˆí‡´ìœ¨ê°œìˆ˜ == 0:
                        self.loc_ê¸‰ë¶€íƒˆí‡´ìœ¨ê°œìˆ˜ = i
                    else:
                        self.loc_ë‚©ë©´íƒˆí‡´ìœ¨ê°œìˆ˜ = i
        
        # Find column locations in ë³´ì¥ë°°ìˆ˜
        if self.data.arr_ë³´ì¥ë°°ìˆ˜ is not None and len(self.data.arr_ë³´ì¥ë°°ìˆ˜) > 1:
            for i in range(len(self.data.arr_ë³´ì¥ë°°ìˆ˜[1])):
                attr_name = str(self.data.arr_ë³´ì¥ë°°ìˆ˜[1][i] or "").strip().replace("\n", "")
                if not attr_name and len(self.data.arr_ë³´ì¥ë°°ìˆ˜) > 0:
                    attr_name = str(self.data.arr_ë³´ì¥ë°°ìˆ˜[0][i] or "").strip().replace("\n", "")
                
                if attr_name == "ì§€ê¸‰ë¥ ":
                    self.loc_ì§€ê¸‰ë¥  = i
                elif attr_name == "ì§€ê¸‰ì°¨ë…„":
                    self.loc_ë¶„í• ì§€ê¸‰ì°¨ë…„ = i
                elif attr_name == "ì—°ì§€ê¸‰íšŸìˆ˜":
                    self.loc_ì—°ì§€ê¸‰íšŸìˆ˜ = i
                elif attr_name == "ë©´ì±…ê¸°ê°„":
                    self.loc_ë©´ì±…ê¸°ê°„ = i
                elif attr_name == "ê°ì•¡ê¸°ê°„":
                    if self.loc_ê°ì•¡ê¸°ê°„ == 0:
                        self.loc_ê°ì•¡ê¸°ê°„ = i
                    else:
                        self.loc_ê°ì•¡ê¸°ê°„2 = i
                elif attr_name == "ê°ì•¡ë¹„ìœ¨":
                    if self.loc_ê°ì•¡ë¹„ìœ¨ == 0:
                        self.loc_ê°ì•¡ë¹„ìœ¨ = i
                    else:
                        self.loc_ê°ì•¡ë¹„ìœ¨2 = i
                elif attr_name == "15ì„¸ë¯¸ë§Œë©´ì±…ì ìš©":
                    self.loc_15ì„¸ë©´ì±… = i
        
        if log_callback:
            log_callback(f"ì»¬ëŸ¼ ìœ„ì¹˜ ë¶„ì„ ì™„ë£Œ: í™•ì¥ë²ˆí˜¸={self.loc_í™•ì¥ë²ˆí˜¸}, ë³´ê¸°ë‚©ê¸°={self.loc_ë³´ê¸°ë‚©ê¸°}")

    def _read_pgm_loop(self, dambo_code: str, dambo_att: DamboAttributes, loop_point: int, log_callback=None):
        """
        Read PGM data for each coverage code.
        Uses numpy arrays for fast lookup (nanosecond access).
        """
        try:
            # Initialize
            self.m_point = 0
            self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ = -1
            self.ì„¸ë¶€ë‹´ë³´ì½”ë“œList = []
            self.isê°ì•¡ë‘ë²ˆ = False
            self.min_riskrate_row = 0
            self.is_ë…íŠ¹ê°„í¸ = False
            
            # ===== M_Point Search (using numpy - FAST!) =====
            arr_main = self.data.arr_pgm_main
            
            if arr_main is not None:
                for mpoint_lookup in range(len(arr_main)):
                    try:
                        row = arr_main[mpoint_lookup]
                        if row[0] is None:
                            continue
                        
                        if self.data.ë…ë¦½íŠ¹ì•½ == 0:
                            # ì¼ë°˜ ë‹´ë³´
                            row_dambo = str(row[1] if len(row) > 1 else "").strip()
                            if row_dambo == dambo_code:
                                self.m_point = mpoint_lookup
                                break
                        else:
                            # ë…ë¦½íŠ¹ì•½
                            row_dambo = str(row[0] if len(row) > 0 else "").strip()
                            row_í˜•êµ¬ë¶„ = str(row[self.loc_í™•ì¥ë²ˆí˜¸] if len(row) > self.loc_í™•ì¥ë²ˆí˜¸ else "").strip()
                            if row_dambo == dambo_code and row_í˜•êµ¬ë¶„ == dambo_att.í˜•êµ¬ë¶„:
                                self.m_point = mpoint_lookup
                                break
                    except:
                        continue
            
            if self.m_point == 0:
                # if log_callback:
                #     log_callback(f"[ê²½ê³ ] M_Pointë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {dambo_code}")
                return
            
            # ===== ë³´ì¥êµ¬ì¡° Lookup Key =====
            if self.data.ë…ë¦½íŠ¹ì•½ == 0:
                if self.m_point < len(arr_main) and self.loc_í™•ì¥ë²ˆí˜¸ < len(arr_main[self.m_point]):
                    dambo = arr_main[self.m_point][self.loc_í™•ì¥ë²ˆí˜¸]
                    ë³´ì¥êµ¬ì¡°_lookup_key = f"{self.data.product_code}_{dambo}"
                else:
                    ë³´ì¥êµ¬ì¡°_lookup_key = ""
            else:
                ë³´ì¥êµ¬ì¡°_lookup_key = f"{dambo_code}_{dambo_att.í˜•êµ¬ë¶„}"
                if self.loc_ë‹´ë³´ê·¸ë£¹ > 0 and self.m_point < len(arr_main):
                    self.ë…íŠ¹ë‹´ë³´ê·¸ë£¹ = arr_main[self.m_point][-1]  # Last column
            
            # ===== ì„¸ë¶€ë‹´ë³´ ê°œìˆ˜/ì½”ë“œ (using numpy) =====
            arr_êµ¬ì¡° = self.data.arr_ë³´ì¥êµ¬ì¡°
            
            if arr_êµ¬ì¡° is not None and ë³´ì¥êµ¬ì¡°_lookup_key:
                for index_lookup in range(len(arr_êµ¬ì¡°)):
                    try:
                        lookup_val = str(arr_êµ¬ì¡°[index_lookup][0]).strip()
                        if lookup_val == ë³´ì¥êµ¬ì¡°_lookup_key:
                            if self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ <= 0:
                                self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ += 1
                            elif arr_êµ¬ì¡°[index_lookup][self.loc_ì„¸ë¶€ë‹´ë³´ìˆœë²ˆ] > self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜:
                                self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ += 1
                            else:
                                break
                            
                            if self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ == 0:
                                self.min_riskrate_row = index_lookup
                            
                            # ì„¸ë¶€ë‹´ë³´ì½”ë“œ ì €ì¥
                            if self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ >= 0 and self.loc_ì„¸ë¶€ë‹´ë³´ì½”ë“œ < len(arr_êµ¬ì¡°[index_lookup]):
                                self.ì„¸ë¶€ë‹´ë³´ì½”ë“œList.append(arr_êµ¬ì¡°[index_lookup][self.loc_ì„¸ë¶€ë‹´ë³´ì½”ë“œ])
                            
                            # ë‹¤ìŒ í–‰ í™•ì¸
                            if index_lookup + 1 >= len(arr_êµ¬ì¡°):
                                break
                            if str(arr_êµ¬ì¡°[index_lookup + 1][0]).strip() != ë³´ì¥êµ¬ì¡°_lookup_key:
                                break
                    except:
                        continue
            
            # ===== ë‚©ì…ë©´ì œì—¬ë¶€ =====
            if arr_êµ¬ì¡° is not None and self.min_riskrate_row < len(arr_êµ¬ì¡°) and self.loc_ë‚©ë©´íƒˆí‡´ìœ¨ê°œìˆ˜ > 0:
                try:
                    if arr_êµ¬ì¡°[self.min_riskrate_row][self.loc_ë‚©ë©´íƒˆí‡´ìœ¨ê°œìˆ˜] > 0:
                        self.ë‚©ì…ë©´ì œì—¬ë¶€ = True
                    else:
                        self.ë‚©ì…ë©´ì œì—¬ë¶€ = False
                except:
                    self.ë‚©ì…ë©´ì œì—¬ë¶€ = False
            
            # ===== ì„¸ë¶€ë‹´ë³´_bencoef ë°°ì—´ ìƒì„± =====
            arr_ë°°ìˆ˜ = self.data.arr_ë³´ì¥ë°°ìˆ˜
            
            if self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜ > 0 and arr_êµ¬ì¡° is not None and arr_ë°°ìˆ˜ is not None:
                self.ì„¸ë¶€ë‹´ë³´_bencoef = []
                for i in range(self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜):
                    try:
                        if self.min_riskrate_row + i + 1 < len(arr_êµ¬ì¡°):
                            ë³´ì¥ë°°ìˆ˜_key = arr_êµ¬ì¡°[self.min_riskrate_row + i + 1][self.loc_ë³´ì¥ë°°ìˆ˜]
                            bencoef_row = self.data.get_array_row(arr_ë°°ìˆ˜, ë³´ì¥ë°°ìˆ˜_key, 0)
                            if bencoef_row is not None:
                                self.ì„¸ë¶€ë‹´ë³´_bencoef.append([0] + list(bencoef_row))
                            else:
                                self.ì„¸ë¶€ë‹´ë³´_bencoef.append([0])
                        else:
                            self.ì„¸ë¶€ë‹´ë³´_bencoef.append([0])
                    except:
                        self.ì„¸ë¶€ë‹´ë³´_bencoef.append([0])
            
            # ===== ë©´ì±…/ê°ì•¡ Summary =====
            self.sum_ë©´ì±… = 0
            self.sum_ê°ì•¡ = 0
            
            for i in range(self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜):
                try:
                    if len(self.ì„¸ë¶€ë‹´ë³´_bencoef[i]) > self.loc_ë©´ì±…ê¸°ê°„:
                        val = self.ì„¸ë¶€ë‹´ë³´_bencoef[i][self.loc_ë©´ì±…ê¸°ê°„]
                        self.sum_ë©´ì±… += float(val or 0)
                    if len(self.ì„¸ë¶€ë‹´ë³´_bencoef[i]) > self.loc_ê°ì•¡ê¸°ê°„:
                        val = self.ì„¸ë¶€ë‹´ë³´_bencoef[i][self.loc_ê°ì•¡ê¸°ê°„]
                        self.sum_ê°ì•¡ += float(val or 0)
                except:
                    pass
            
            # ===== ê°ì•¡íšŸìˆ˜ =====
            for i in range(self.ì„¸ë¶€ë‹´ë³´ê°œìˆ˜):
                try:
                    if (len(self.ì„¸ë¶€ë‹´ë³´_bencoef[i]) > self.loc_ê°ì•¡ê¸°ê°„2 and 
                        len(self.ì„¸ë¶€ë‹´ë³´_bencoef[i]) > self.loc_ê°ì•¡ë¹„ìœ¨2):
                        if (self.ì„¸ë¶€ë‹´ë³´_bencoef[i][self.loc_ê°ì•¡ê¸°ê°„2] > 0 and 
                            self.ì„¸ë¶€ë‹´ë³´_bencoef[i][self.loc_ê°ì•¡ë¹„ìœ¨2] > 0):
                            self.isê°ì•¡ë‘ë²ˆ = True
                            break
                except:
                    pass
            
            # ===== ë³´ê¸°ë‚©ê¸° ì²˜ë¦¬ =====
            self._read_pgm_ë³´ê¸°ë‚©ê¸°(dambo_att, log_callback)
            
            # ===== ì„¸ë¶€ë³´ì¥ëª…_list ì—…ë°ì´íŠ¸ (PGM êµ¬ì¡° ìš°ì„ ) =====
            # PGMì—ì„œ ì„¸ë¶€ë‹´ë³´ì½”ë“œê°€ ë°œê²¬ë˜ì—ˆë‹¤ë©´, ì´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì„¸ë¶€ë³´ì¥ëª…_listì— ë°˜ì˜
            if self.ì„¸ë¶€ë‹´ë³´ì½”ë“œList and self.data.arr_ë‹´ë³´ë§¤í•‘ is not None:
                new_sembo_list = []
                # ë‹´ë³´ë§¤í•‘ì—ì„œ ì½”ë“œ->ëª…ì¹­ ì¡°íšŒ (Fast lookup using numpy)
                # ë‹´ë³´ë§¤í•‘ êµ¬ì¡°: [ëŒ€í‘œë‹´ë³´ì½”ë“œ, ëŒ€í‘œë‹´ë³´ëª…, ë‹´ë³´ì½”ë“œ, ë‹´ë³´ëª…, ...]
                # Index 2: ë‹´ë³´ì½”ë“œ, Index 3: ë‹´ë³´ëª…
                
                arr_mapping = self.data.arr_ë‹´ë³´ë§¤í•‘
                
                for sembo_code in self.ì„¸ë¶€ë‹´ë³´ì½”ë“œList:
                    try:
                        # Find row where col[2] == sembo_code
                        row = self.data.get_array_row(arr_mapping, sembo_code, 2)
                        if row is not None and len(row) > 3:
                            sembo_name = str(row[3] or "").strip()
                            if sembo_name:
                                new_sembo_list.append(sembo_name)
                            else:
                                new_sembo_list.append(sembo_code) # ì´ë¦„ì—†ìœ¼ë©´ ì½”ë“œë¼ë„
                        else:
                             # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ì½”ë“œ ìì²´ ì‚¬ìš© or Skip?
                             # ë³´í†µ ë§¤í•‘ì´ ìˆì–´ì•¼ í•¨. ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë³´ë‹¤ ì½”ë“œê°€ ë‚˜ìŒ.
                             new_sembo_list.append(sembo_code)
                    except:
                        pass
                
                if new_sembo_list:
                    dambo_att.ì„¸ë¶€ë³´ì¥ëª…_list = new_sembo_list
                    # if log_callback:
                    #     log_callback(f"      ì„¸ë¶€ë³´ì¥ëª…_list ì—…ë°ì´íŠ¸(PGM): {new_sembo_list}")

        except Exception as e:
            if log_callback:
                log_callback(f"[ì—ëŸ¬] _read_pgm_loop: {e}")

    def _read_pgm_ë³´ê¸°ë‚©ê¸°(self, dambo_att: DamboAttributes, log_callback=None):
        """
        Read ë³´ê¸°ë‚©ê¸° data using numpy arrays.
        """
        try:
            self.n_array = []
            self.age_b = 999
            self.age_e = 0
            
            # TERM_Lookup_Key ìƒì„±
            arr_main = self.data.arr_pgm_main
            
            if arr_main is not None and self.m_point < len(arr_main):
                if self.data.ë…ë¦½íŠ¹ì•½ == 0:
                    if self.loc_ë³´ê¸°ë‚©ê¸° < len(arr_main[self.m_point]):
                        ë³´ê¸°ë‚©ê¸°ê°’ = arr_main[self.m_point][self.loc_ë³´ê¸°ë‚©ê¸°]
                        self.term_lookup_key = f"{self.data.product_code}_{ë³´ê¸°ë‚©ê¸°ê°’}"
                    else:
                        self.term_lookup_key = ""
                else:
                    if self.loc_ë³´ê¸°ë‚©ê¸° < len(arr_main[self.m_point]):
                        ë³´ê¸°ë‚©ê¸°ê°’ = arr_main[self.m_point][self.loc_ë³´ê¸°ë‚©ê¸°]
                        self.term_lookup_key = str(ë³´ê¸°ë‚©ê¸°ê°’)
                    else:
                        self.term_lookup_key = ""
            
            # N ë°°ì—´ ì €ì¥ (using numpy - FAST!)
            arr_ë³´ê¸° = self.data.arr_ë³´ê¸°ë‚©ê¸°
            
            if arr_ë³´ê¸° is not None and self.term_lookup_key:
                for index_lookup in range(len(arr_ë³´ê¸°)):
                    try:
                        lookup_val = str(arr_ë³´ê¸°[index_lookup][0]).strip()
                        if lookup_val == self.term_lookup_key:
                            # Age_B, Age_E ì €ì¥
                            age_b_val = arr_ë³´ê¸°[index_lookup][8] if len(arr_ë³´ê¸°[index_lookup]) > 8 else 0
                            age_e_val = arr_ë³´ê¸°[index_lookup][9] if len(arr_ë³´ê¸°[index_lookup]) > 9 else 0
                            
                            self.age_b = min(self.age_b, int(age_b_val) if age_b_val else 0)
                            self.age_e = max(self.age_e, int(age_e_val) if age_e_val else 0)
                            
                            # N ë°°ì—´ì— ì¶”ê°€
                            n_entry = [
                                arr_ë³´ê¸°[index_lookup][6] if len(arr_ë³´ê¸°[index_lookup]) > 6 else "",
                                arr_ë³´ê¸°[index_lookup][11] if len(arr_ë³´ê¸°[index_lookup]) > 11 else "",
                                arr_ë³´ê¸°[index_lookup][12] if len(arr_ë³´ê¸°[index_lookup]) > 12 else ""
                            ]
                            self.n_array.append(n_entry)
                    except:
                        continue
            
            if self.age_b == 999:
                self.age_b = 0
                
        except Exception as e:
            if log_callback:
                log_callback(f"[ì—ëŸ¬] _read_pgm_ë³´ê¸°ë‚©ê¸°: {e}")

    def _set_ë…íŠ¹_file_path(self, dambo_att: DamboAttributes, ëŒ€í‘œë‹´ë³´ì½”ë“œ: str, dambo_code: str, log_callback=None):
        """
        ë…ë¦½íŠ¹ì•½ íŒŒì¼ ê²½ë¡œ ì¬ì§€ì • ë° ê°ì•¡ë©´ì±…ì—¬ë¶€ ì €ì¥.
        Uses numpy arrays for fast lookup.
        """
        try:
            # íŒŒì¼ê²½ë¡œ ì¬ì§€ì •
            arr_íŒŒì¼ëª… = self.data.arr_ë…íŠ¹íŒŒì¼ëª…
            if arr_íŒŒì¼ëª… is not None:
                for i in range(len(arr_íŒŒì¼ëª…)):
                    if arr_íŒŒì¼ëª…[i][0] == self.ë…íŠ¹ë‹´ë³´ê·¸ë£¹:
                        if self.is_ë…íŠ¹ê°„í¸:
                            self.data.ì•½ê´€íŒŒì¼ëª… = str(arr_íŒŒì¼ëª…[i][2])
                        else:
                            self.data.ì•½ê´€íŒŒì¼ëª… = str(arr_íŒŒì¼ëª…[i][1])
                        
                        # ë…ë¦½íŠ¹ì•½ëª… ì¶”ì¶œ
                        ì•½ê´€íŒŒì¼ëª… = self.data.ì•½ê´€íŒŒì¼ëª…
                        if ì•½ê´€íŒŒì¼ëª…:
                            start_idx = ì•½ê´€íŒŒì¼ëª….find("ì•½ê´€_")
                            if start_idx >= 0:
                                end_idx = ì•½ê´€íŒŒì¼ëª….find("_", start_idx + 3)
                                if end_idx > start_idx:
                                    self.ë…ë¦½íŠ¹ì•½ëª… = ì•½ê´€íŒŒì¼ëª…[start_idx + 3:end_idx]
                        break
            
            # ê°ì•¡ë©´ì±…ì—¬ë¶€ ì €ì¥
            arr_ë ˆì´ì•„ì›ƒ = self.data.arr_ë…íŠ¹ë ˆì´ì•„ì›ƒ
            if arr_ë ˆì´ì•„ì›ƒ is not None:
                layout_key = f"{dambo_code}_{dambo_att.í˜•êµ¬ë¶„}"
                for i in range(len(arr_ë ˆì´ì•„ì›ƒ)):
                    if str(arr_ë ˆì´ì•„ì›ƒ[i][0]).strip() == layout_key:
                        if "X" in str(arr_ë ˆì´ì•„ì›ƒ[i][7]):
                            dambo_att.ë…íŠ¹ê°ì•¡ì—¬ë¶€ = "ê°ì•¡ì—†ìŒ"
                        else:
                            dambo_att.ë…íŠ¹ê°ì•¡ì—¬ë¶€ = "ê°ì•¡ìˆìŒ"
                        
                        if "X" in str(arr_ë ˆì´ì•„ì›ƒ[i][8]):
                            dambo_att.ë…íŠ¹ë©´ì±…ì—¬ë¶€ = "ë©´ì±…ì—†ìŒ"
                        else:
                            dambo_att.ë…íŠ¹ë©´ì±…ì—¬ë¶€ = "ë©´ì±…ìˆìŒ"
                        break
                        
        except Exception as e:
            if log_callback:
                log_callback(f"[ì—ëŸ¬] _set_ë…íŠ¹_file_path: {e}")

    def _copy_terms(self, ëŒ€í‘œë‹´ë³´ì½”ë“œ: str, íŠ¹ë³„ì•½ê´€ê²½ë¡œ: str, íŠ¹ë³„ì•½ê´€íŒŒì¼ëª…: str, 
                    dambo_category: str, dambo_att: DamboAttributes, log_callback=None):
        """
        Copy terms from source document to target document.
        Based on VBA Copy_ì•½ê´€ logic.
        """
        try:
            # Use pre-cached source document (opened before main loop)
            source_doc = None
            if hasattr(self, 'source_docs') and self.source_docs:
                source_doc = self.source_docs.get(dambo_category)
                if not source_doc and self.source_docs:
                    # Fallback to first available
                    source_doc = list(self.source_docs.values())[0]
            
            if not source_doc:
                if log_callback:
                    log_callback(f"   âš ï¸ ì†ŒìŠ¤ ë¬¸ì„œ ì—†ìŒ: {dambo_category}")
                return
            
            # Use pre-opened target document
            target_doc = self.word.target_doc
            if not target_doc:
                if log_callback:
                    log_callback(f"   âš ï¸ íƒ€ê²Ÿ ë¬¸ì„œ ì—†ìŒ")
                return
            
            # Find the coverage code in source document comments
            copy_range = None
            found_start = False
            íŠ¹ë³„ì•½ê´€ëª… = None
            
            if log_callback:
                log_callback(f"   ğŸ” ì£¼ì„ì—ì„œ '{ëŒ€í‘œë‹´ë³´ì½”ë“œ}' ê²€ìƒ‰ ì¤‘...")
            
            for comment in source_doc.Comments:
                comment_text = str(comment.Range.Text)
                codes = [c.strip() for c in comment_text.split(",")]
                
                if not found_start:
                    if ëŒ€í‘œë‹´ë³´ì½”ë“œ in codes:
                        # VBA: íŠ¹ë³„ì•½ê´€ëª…ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬ (ì˜ˆ: "êµí†µìƒí•´í›„ìœ ì¥í•´")
                        # ì´ ê°’ì€ comment.Scope.Paragraphs(1)ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
                        para = comment.Scope.Paragraphs(1)
                        íŠ¹ë³„ì•½ê´€ëª… = str(para.Range.Text).strip().replace('\r', '').replace('\n', '')
                        
                        # Check if already copied using íŠ¹ë³„ì•½ê´€ëª… key
                        if íŠ¹ë³„ì•½ê´€ëª… in self.copied_list_strings:
                            if log_callback:
                                log_callback(f"   â­ï¸ ì´ë¯¸ ë³µì‚¬ë¨: {íŠ¹ë³„ì•½ê´€ëª…}")
                            return
                        
                        self.copied_list_strings.add(íŠ¹ë³„ì•½ê´€ëª…)
                        copy_range = source_doc.Range(para.Range.Start, para.Range.Start)
                        found_start = True
                        if log_callback:
                            log_callback(f"   âœ… ì‹œì‘ ìœ„ì¹˜ ë°œê²¬: {ëŒ€í‘œë‹´ë³´ì½”ë“œ}")
                else:
                    # Found end marker (next comment)
                    copy_range.End = comment.Scope.Paragraphs(1).Range.Start
                    if log_callback:
                        log_callback(f"   âœ… ì¢…ë£Œ ìœ„ì¹˜ ë°œê²¬")
                    break
            
            if copy_range and copy_range.Start != copy_range.End:
                # Find paste location in target (at END of section)
                if log_callback:
                    log_callback(f"   ğŸ” ì‚½ì… ìœ„ì¹˜ ê²€ìƒ‰: {dambo_category}")
                paste_range = self._find_paste_location(target_doc, dambo_category, dambo_att, log_callback)
                
                if paste_range:
                    # VBA: ë¶™ì—¬ë„£ê¸°ì˜ì—­.FormattedText = ë³µì‚¬ì˜ì—­.FormattedText
                    # InsertAfterë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ ë§¨ ë’¤ì— ì‚½ì…
                    paste_range.InsertAfter("\r")  # ë‹¨ë½ êµ¬ë¶„ ì¶”ê°€
                    paste_range.Collapse(0)  # wdCollapseEnd = 0
                    
                    # Capture Start Position BEFORE Paste
                    start_pos = paste_range.Start
                    
                    # Paste Content
                    paste_range.FormattedText = copy_range.FormattedText
                    
                    # Capture End Position AFTER Paste
                    # Note: When FormattedText is set, the Range object usually expands to include new text.
                    end_pos = paste_range.End
                    
                    # Re-verify range validity
                    if end_pos <= start_pos:
                        # Fallback: If range didn't expand, try to expand to end of current paragraph
                        # This works because we inserted at the end of a section
                        try:
                            # Try to expand to at least some content
                            end_pos = paste_range.Paragraphs(1).Range.End
                        except:
                            pass
                    
                    # Create explicit range for the pasted content
                    try:
                        if end_pos <= start_pos + 5: # Allow small buffer
                            # Fallback: Recalculate end position using section markers
                            if log_callback:
                                log_callback(f"   âš ï¸ Range not expanded. Recalculating end position...")
                            result_range = self._recalculate_paste_range_end(target_doc, start_pos, log_callback)
                        else:
                            result_range = target_doc.Range(start_pos, end_pos)
                    except Exception as e:
                        if log_callback:
                            log_callback(f"   âš ï¸ Range creation failed: {e}")
                        result_range = paste_range  # Fallback to original object
                    
                    if log_callback:
                        captured_text_preview = result_range.Text[:100].replace('\r', '\\r').replace('\n', '\\n') if result_range else "None"
                        print(f"      [DEBUG] Captured Range Text ({start_pos}~{result_range.End if result_range else '?'}: {captured_text_preview}")
                        log_callback(f"   âœ… ë³µì‚¬ ì™„ë£Œ: {ëŒ€í‘œë‹´ë³´ì½”ë“œ} â†’ {dambo_category} ì„¹ì…˜ ë (Range: {start_pos}~{end_pos})")
                    
                    return result_range
                else:
                    if log_callback:
                        log_callback(f"   âš ï¸ ë¶™ì—¬ë„£ê¸° ìœ„ì¹˜ ì—†ìŒ: {ëŒ€í‘œë‹´ë³´ì½”ë“œ}")
            else:
                if log_callback:
                    log_callback(f"   âš ï¸ ë³µì‚¬ ë²”ìœ„ ì—†ìŒ: {ëŒ€í‘œë‹´ë³´ì½”ë“œ}")
            
            return None
                    
        except Exception as e:
            if log_callback:
                log_callback(f"   âŒ ì•½ê´€ ë³µì‚¬ ì—ëŸ¬: {e}")
            import traceback
            traceback.print_exc()

    def _find_paste_location(self, target_doc, dambo_category: str, dambo_att: DamboAttributes, log_callback=None):
        """
        Find paste location in target document - at the END of the section.
        Based on VBA logic: find section start, then find next section marker to get end position.
        ì„¹ì…˜ í˜•ì‹: "ìƒí™œì•ˆì •ëª¨ë“ˆ-ìƒí•´ê´€ë ¨ íŠ¹ë³„ì•½ê´€" (ì½”ë©˜íŠ¸)
        """
        # Debug: ëª¨ë“ˆí˜• ê°’ í™•ì¸
        ëª¨ë“ˆí˜•_val = getattr(self.data, 'ëª¨ë“ˆí˜•', 0)
        if log_callback:
            # log_callback(f"      DEBUG: ëª¨ë“ˆí˜•={ëª¨ë“ˆí˜•_val}, dambo_att.ëª¨ë“ˆ='{dambo_att.ëª¨ë“ˆ}'")
            pass
        
        # ì„¹ì…˜ íƒ€ì´í‹€ í˜•ì‹: "ìƒí™œì•ˆì •ëª¨ë“ˆ-ìƒí•´ê´€ë ¨ íŠ¹ë³„ì•½ê´€"
        # ëª¨ë“ˆí˜•=1 ì´ê±°ë‚˜ dambo_att.ëª¨ë“ˆì— ê°’ì´ ìˆìœ¼ë©´ ëª¨ë“ˆí˜•ìœ¼ë¡œ ì²˜ë¦¬
        if (ëª¨ë“ˆí˜•_val == 1 or dambo_att.ëª¨ë“ˆ) and dambo_att.ëª¨ë“ˆ:
            section_title = f"{dambo_att.ëª¨ë“ˆ}-{dambo_category}ê´€ë ¨ íŠ¹ë³„ì•½ê´€"
        else:
            # ë¹„ëª¨ë“ˆí˜•: "ìƒí•´ê´€ë ¨ íŠ¹ë³„ì•½ê´€"
            section_title = f"{dambo_category}ê´€ë ¨ íŠ¹ë³„ì•½ê´€"
        
        if log_callback:
            log_callback(f"      ì„¹ì…˜ ê²€ìƒ‰: {section_title}")
        
        section_start = None
        section_end = None
        found_section = False
        
        # Search in comments for section boundaries
        for comment in target_doc.Comments:
            comment_text = str(comment.Range.Text)
            
            if not found_section:
                # Find the start of our section
                if section_title in comment_text:
                    section_start = comment.Scope.Paragraphs(1).Range
                    found_section = True
                    if log_callback:
                        log_callback(f"      âœ… ì„¹ì…˜ ì‹œì‘ ë°œê²¬")
            else:
                # Find the end - next section marker (ë‹¤ìŒ ì„¹ì…˜ ë˜ëŠ” ë³„í‘œ)
                # íŒ¨í„´: "ëª¨ë“ˆ-ì¹´í…Œê³ ë¦¬ê´€ë ¨ íŠ¹ë³„ì•½ê´€" ë˜ëŠ” "ë³„í‘œ"
                if any(marker in comment_text for marker in 
                       ["ê´€ë ¨ íŠ¹ë³„ì•½ê´€", "ì œë„ì„± íŠ¹ë³„ì•½ê´€", "ë³„í‘œ"]):
                    # í˜„ì¬ ì„¹ì…˜ê³¼ ë‹¤ë¥¸ ì„¹ì…˜ì´ë©´ ë
                    if section_title not in comment_text:
                        # End is just before this next section
                        section_end = target_doc.Range(
                            section_start.End,
                            comment.Scope.Paragraphs(1).Range.Start - 1
                        )
                        if log_callback:
                            log_callback(f"      âœ… ì„¹ì…˜ ë ë°œê²¬: {comment_text[:30]}...")
                        break
        
        if section_end:
            # Return the range at the END of the section (before next section)
            return section_end
        elif section_start:
            # If no next section found, use end of section_start paragraph
            # Find the last paragraph in this section
            return section_start
        
        return None

    def _revise_terms(self, dambo_att: DamboAttributes, loop_point: int, target_range, log_callback=None):
        """
        Revise terms with specific attribute values using TagProcessor.
        Handles substitution tags and output control tags within the specified range.
        
        Args:
            dambo_att: DamboAttributes
            loop_point: Loop index
            target_range: Word Range object to process (e.g., pasted text)
        """
        try:
            if log_callback:
                log_callback(f"   ğŸ·ï¸ íƒœê·¸ ì²˜ë¦¬ ì‹œì‘: {dambo_att.ë‹´ë³´ì½”ë“œ}")
            
            # Create TagContext from DamboAttributes
            context = create_tag_context_from_dambo_att(dambo_att, self.data)
            
            # Set additional context from PGM data
            context.ë©´ì±… = 1 if self.sum_ë©´ì±… > 0 else 0
            context.ê°ì•¡ = 1 if self.sum_ê°ì•¡ > 0 else 0
            context.ê°ì•¡í•œë²ˆ = not self.isê°ì•¡ë‘ë²ˆ
            context.ê°ì•¡ë‘ë²ˆ = self.isê°ì•¡ë‘ë²ˆ
            context.ë…ë¦½íŠ¹ì•½ = self.data.ë…ë¦½íŠ¹ì•½
            context.ë¹„ê°±ì‹  = 1 if self.data.ìë™ê°±ì‹ í˜• == 0 else 0
            
            if log_callback:
                log_callback(f"      ë©´ì±…={context.ë©´ì±…}, ê°ì•¡={context.ê°ì•¡}, ì—°ì¥í˜•={dambo_att.ì—°ì¥í˜•}")
            
            # Build ê°ì•¡ê¸°ê°„ list from PGM
            if self.ì„¸ë¶€ë‹´ë³´_bencoef:
                for bencoef in self.ì„¸ë¶€ë‹´ë³´_bencoef:
                    ê¸°ê°„_list = []
                    # Check safe access
                    if len(bencoef) > self.loc_ê°ì•¡ê¸°ê°„ and bencoef[self.loc_ê°ì•¡ê¸°ê°„]:
                        try:
                            ê¸°ê°„_list.append(int(bencoef[self.loc_ê°ì•¡ê¸°ê°„]))
                        except (ValueError, TypeError):
                            pass
                    if len(bencoef) > self.loc_ê°ì•¡ê¸°ê°„2 and bencoef[self.loc_ê°ì•¡ê¸°ê°„2]:
                        try:
                            ê¸°ê°„_list.append(int(bencoef[self.loc_ê°ì•¡ê¸°ê°„2]))
                        except (ValueError, TypeError):
                            pass
                    
                    if ê¸°ê°„_list:
                        context.ê°ì•¡ê¸°ê°„_list.append(ê¸°ê°„_list)
            
            # Build ì§€ê¸‰ë¥  data from PGM
            if self.ì„¸ë¶€ë‹´ë³´_bencoef and context.ëŒ€í‘œë‹´ë³´ì½”ë“œ:
                ì§€ê¸‰ë¥ _list = []
                for bencoef in self.ì„¸ë¶€ë‹´ë³´_bencoef:
                    if len(bencoef) > self.loc_ì§€ê¸‰ë¥  and bencoef[self.loc_ì§€ê¸‰ë¥ ]:
                        try:
                            ì§€ê¸‰ë¥ _list.append([float(bencoef[self.loc_ì§€ê¸‰ë¥ ])])
                        except (ValueError, TypeError):
                            ì§€ê¸‰ë¥ _list.append([100.0])
                    else:
                        ì§€ê¸‰ë¥ _list.append([100.0])
                context.ì§€ê¸‰ë¥ _data[context.ëŒ€í‘œë‹´ë³´ì½”ë“œ] = ì§€ê¸‰ë¥ _list
            
            # Process tags in target RANGE
            if target_range:
                self.tag_processor.csv_loader = self.csv_loader if hasattr(self, 'csv_loader') else None
                self.tag_processor.process_range(target_range, context, log_callback)
            else:
                if log_callback:
                    log_callback(f"   âš ï¸ target_range ì—†ìŒ - íƒœê·¸ ì²˜ë¦¬ ìŠ¤í‚µ")
                
        except Exception as e:
            if log_callback:
                log_callback(f"   âŒ [ì—ëŸ¬] _revise_terms: {e}")
            import traceback
            traceback.print_exc()

    def _revise_ë³„í‘œ_0ì„¸(self, log_callback=None):
        """
        Handle 0ì„¸ (zero age) child related revisions.
        Processes 0ì„¸ìë…€ related tags.
        """
        try:
            if self.data.zero_age_ìë…€ == 0:
                return  # No 0ì„¸ìë…€ processing needed
            
            if log_callback:
                log_callback("0ì„¸ìë…€ íƒœê·¸ ì²˜ë¦¬ ì¤‘...")
            
            # Process 0ì„¸ìë…€ specific tags
            # TODO: Implement specific 0ì„¸ìë…€ tag processing
            
            if log_callback:
                log_callback("0ì„¸ìë…€ íƒœê·¸ ì²˜ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            if log_callback:
                log_callback(f"[ì—ëŸ¬] _revise_ë³„í‘œ_0ì„¸: {e}")
    def _recalculate_paste_range_end(self, target_doc, start_pos, log_callback=None):
        """
        Calculates the end position of the pasted content by finding the next section or end of document.
        """
        try:
            # Search for the next section marker starting from start_pos
            search_range = target_doc.Range(start_pos, target_doc.Content.End)
            
            # Find next section or end of doc
            search_range.Find.ClearFormatting()
            found = False
            
            # Markers that indicate start of a new section
            markers = ["ê´€ë ¨ íŠ¹ë³„ì•½ê´€", "ì œë„ì„± íŠ¹ë³„ì•½ê´€", "ë³„í‘œ"]
            
            min_end_pos = target_doc.Content.End
            
            for marker in markers:
                search_range.Find.Execute(FindText=marker, Forward=True, Wrap=0)
                if search_range.Find.Found:
                    # Found a marker. The end of our section is before this marker's paragraph.
                    # Move to start of the paragraph containing the marker
                    marker_para_start = search_range.Paragraphs(1).Range.Start
                    if marker_para_start < min_end_pos and marker_para_start > start_pos:
                        min_end_pos = marker_para_start
                        found = True
                
                # Reset search range for next marker check
                search_range = target_doc.Range(start_pos, target_doc.Content.End)
            
            return target_doc.Range(start_pos, min_end_pos)
            
        except Exception as e:
            if log_callback:
                log_callback(f"   âš ï¸ Range calculation error: {e}")
            return target_doc.Range(start_pos, target_doc.Content.End)
